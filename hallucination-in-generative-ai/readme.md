# Hallucination in Generative Artificial Intelligence: Challenges, Causes and Mitigation Strategies

**Course:** DLMAISAIS01 â€“ Seminar: AI and Society  
**Program:** Master of Science in Artificial Intelligence  
**Institution:** IU Internationale Hochschule, Germany  

## Abstract
This research essay examines the phenomenon of hallucination in generative artificial intelligence systems, with a focus on large language models. It explores the underlying causes of hallucinations, including data limitations, probabilistic generation, and model architecture, and evaluates their implications for reliability, trust, and societal impact. The paper further discusses existing and emerging mitigation strategies aimed at reducing hallucinations and improving model robustness.

## Scope of the Paper
- Definition and taxonomy of hallucinations in generative AI  
- Technical and data-driven causes  
- Societal and ethical implications  
- Mitigation strategies and evaluation approaches  

## Note
This paper was written as part of academic coursework and reflects ongoing research during the MSc program. Future versions may expand the analysis with empirical evaluation and comparative studies.

**Author:** Himanshu Saxena

